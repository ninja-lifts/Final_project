
# Hand Gesture Recognition Using Machine Learning
  - Objective: Built a machine learning model to classify hand gestures for the English alphabet (A-Z) using Mediapipe, OpenCV, and Scikit-learn.
 ## Key Steps:
   - Data Collection: Collected 26 classes of hand gesture data (A-Z) using OpenCV from live camera feed.
   - Feature Extraction: Used Mediapipeâ€™s hand landmarks to extract key hand features and normalized coordinates for training.
   - Model Development: Trained Random Forest Classifier , logistic regression and K-Nearest Neighbour classifier, achieving the highest accuracy of [100]% with Random Forest.
 ## Key Libraries:
   - Mediapipe: Hand tracking and feature extraction.
   - OpenCV: Data collection from webcam and real-time visualization.
   - Scikit-learn: Model training, testing, and evaluation.
   - Pickle: Model serialization for deployment.
 ## What I Learned:
   - Preprocessing image data for machine learning workflows.
   - Feature extraction using Mediapipe for efficient hand gesture recognition.
   - Model evaluation, including accuracy and selecting optimal classifiers for better predictions.
   - Leveraging Python libraries to streamline real-time data processing and prediction.

